{"cells": [{"cell_type": "code", "execution_count": 2, "id": "ad3c1b02-1deb-4f14-a3d6-da5b1841b756", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/08/23 08:52:13 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n25/08/23 08:52:13 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n25/08/23 08:52:13 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n25/08/23 08:52:13 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"}], "source": "from  pyspark.sql import  SparkSession, functions as f\n\n# Creating Spark session\nspark =SparkSession.builder\\\n                   .appName(\"HealthCare Claims Ingestion\")\\\n                   .getOrCreate()"}, {"cell_type": "code", "execution_count": 14, "id": "a1905f25-be1e-4dca-ac6c-70055e9d432d", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 21:=============================>                            (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------+-------------+------------+-----------+----------+-------+-----------+----------+----------------+-----------+----------+-----------+----------+----------+-----------+-----+----------+------------+----------+\n|ClaimID    |TransactionID|PatientID   |EncounterID|ProviderID|DeptID |ServiceDate|ClaimDate |PayorID         |ClaimAmount|PaidAmount|ClaimStatus|PayorType |Deductible|Coinsurance|Copay|InsertDate|ModifiedDate|datasource|\n+-----------+-------------+------------+-----------+----------+-------+-----------+----------+----------------+-----------+----------+-----------+----------+----------+-----------+-----+----------+------------+----------+\n|CLAIM000054|TRANS006567  |HOSP1-001387|ENC001081  |PROV0194  |DEPT008|2024-06-25 |2024-07-27|Medicaid        |3430.7     |2409.03   |Rejected   |Private   |114.75    |88.9       |7.49 |2021-07-28|2024-08-30  |hosb      |\n|CLAIM000339|TRANS004459  |HOSP1-002776|ENC004331  |PROV0180  |DEPT017|2024-02-17 |2024-06-07|BlueCross       |2401.71    |3736.62   |Pending    |Government|294.68    |34.7       |24.16|2023-11-15|2020-03-15  |hosb      |\n|CLAIM000401|TRANS003989  |HOSP1-001329|ENC007140  |PROV0098  |DEPT009|2024-10-31 |2024-09-25|BlueCross       |1157.16    |417.29    |Pending    |Self-pay  |90.58     |91.6       |41.48|2020-06-10|2024-01-23  |hosb      |\n|CLAIM000514|TRANS009368  |HOSP1-001980|ENC000458  |PROV0218  |DEPT011|2024-08-03 |2024-10-22|UnitedHealthcare|1500.83    |3941.78   |Approved   |Private   |324.89    |50.69      |9.93 |2021-05-24|2020-10-23  |hosb      |\n|CLAIM001408|TRANS000863  |HOSP1-000320|ENC008491  |PROV0022  |DEPT002|2024-09-12 |2024-08-19|UnitedHealthcare|566.21     |2138.3    |Paid       |Government|467.39    |97.89      |27.32|2020-04-01|2022-07-16  |hosb      |\n+-----------+-------------+------------+-----------+----------+-------+-----------+----------+----------------+-----------+----------+-----------+----------+----------+-----------+-----+----------+------------+----------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#configuring variables\nBUCKET_NAME = \"healthcare-bucket-14082025\"\nCLAIMS_BUCKET_PATH = f\"gs://{BUCKET_NAME}/landing/claims/*.csv\"\nBQ_TABLE = \"infra-memento-469009-a5.bronze_dataset.claims\"\nTEMP_GCS_BUCKET = f\"{BUCKET_NAME}/temp\"\n\n\n\n#reading from claims source\nclaims_df = spark.read.csv(CLAIMS_BUCKET_PATH, header = True)\n\nclaims_df = claims_df.withColumn(\n    \"filename\",\n    f.regexp_extract(f.input_file_name(), r\"([^/]+$)\", 1)\n)\n\nclaims_df = claims_df.dropDuplicates()\\\n                     .withColumn(\n                                 \"datasource\",\n                                 f.when(f.col(\"filename\").like(\"%hospital2%\"), \"hosb\")\n                                 .when(f.col(\"filename\").like(\"%hospital1%\"), \"hosa\")\n                                 .otherwise(\"None\")\n                                )\n\nclaims_df = claims_df.drop(\"filename\")\n\nclaims_df.show(5, truncate=False)\n"}, {"cell_type": "code", "execution_count": 15, "id": "19477972-b8c2-4ec0-a23d-83a38b527dd4", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#writing to BigQuery\nclaims_df.write\\\n         .format(\"bigquery\")\\\n         .option(\"table\", BQ_TABLE)\\\n         .option(\"temporaryGcsBucket\", TEMP_GCS_BUCKET)\\\n         .mode(\"overwrite\")\\\n         .save()"}, {"cell_type": "code", "execution_count": null, "id": "d50d75f2-a423-4906-ac6f-1dcc0d32a243", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}